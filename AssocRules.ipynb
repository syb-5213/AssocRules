{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码仓库：https://github.com/syb-5213/AssocRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import  linear_model\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.对数据集进行处理，转换成适合进行关联规则挖掘的形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据并打印所有属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cbg_patterns.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "属性有: census_block_group、date_range_start、date_range_end、raw_visit_count、raw_visitor_count、visitor_home_cbgs、visitor_work_cbgs、distance_from_home、related_same_day_brand、related_same_month_brand、top_brands、popularity_by_hour、popularity_by_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择属性related_same_day_brand（属性related_same_month_brand以及top_brands处理过程类似）进行关联规则的挖掘,首先将数据集变为易于挖掘关联规则的格式,代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=data[\"related_same_day_brand\"]\n",
    "all_data=[]\n",
    "for i in range(len(a)):\n",
    "    b=a.iloc[[i]].values[0]\n",
    "    c=b[1:len(b)-1]\n",
    "    if(not(len(c)==0)):\n",
    "        t_data=[]\n",
    "        d=c.split(',')\n",
    "        for j in range(len(d)):\n",
    "            e=d[j][1:len(d[j])-1]\n",
    "            t_data.append(e)\n",
    "        all_data.append(t_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换格式后的数据保存在all_data变量中，如下列出一些转换后的数据格式，每一项记录代表一个人访问过哪些品牌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chick-fil-A', 'mcdonalds', 'Marathon Petroleum', 'walmart']\n",
      "['Shell Oil', 'mcdonalds', 'Chick-fil-A', 'Chevron']\n",
      "['Dollar General']\n",
      "['Chick-fil-A', \"Sam's Club\", 'Dollar General', 'walmart']\n",
      "['Chevron', 'Daylight Donuts', 'walmart']\n",
      "['walmart']\n",
      "['walmart', 'Chick-fil-A']\n",
      "['The American Legion', 'Dollar General', \"Jack's Family Restaurants\"]\n",
      "[\"Papa Murphy's\", 'starbucks', 'Holiday Station']\n",
      "['Burger King US', 'ConocoPhillips', 'SUBWAY', 'Chevron', 'Ace Hardware', 'Shell Oil', 'mcdonalds', \"Denny's\"]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_data)):\n",
    "    if(i<10):\n",
    "        print(all_data[i])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.找出频繁模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于数据项比较多，采用fp树的方式进行频繁模式的挖掘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先对上述处理后的数据进一步压缩，合并相同项集并用count记录该项集出现的次数，代码如create_comb_data函数所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comb_data(data):\n",
    "    comb_data={}\n",
    "    for i in data:\n",
    "        key = frozenset(i)\n",
    "        if key in comb_data:\n",
    "            comb_data[frozenset(i)] += 1\n",
    "        else:\n",
    "            comb_data[frozenset(i)] = 1\n",
    "    return comb_data\n",
    "comb_data = create_comb_data(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建fp树的结点类node，其中name用于存放结点名字，count用于计数，nodeLink用于连接相似结点，parent用于存放父节点，用于回溯，children存放儿子结点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self, name, counts, parent_node):\n",
    "        self.name = name\n",
    "        self.count = counts\n",
    "        self.nodeLink = None\n",
    "        self.parent = parent_node\n",
    "        self.children = {}\n",
    "\n",
    "    def add(self, counts):\n",
    "        self.count += counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来开始构建fp树如函数crerat_fp_tree所示，参数minSupport表示最小支持度（为方便起见这里以及后面采用次数作为支持度而不用比率），代码中的注释详细解释了每部分的作用，其中update_FPtree函数递归的生成课件中的纵向链表，update_item_list函数递归的生成课件中每个table表中item的横向链表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_item_list(node1, node2):\n",
    "    while node1.nodeLink != None:\n",
    "        node1 = node1.nodeLink\n",
    "    node1.nodeLink = node2\n",
    "def update_FPtree(items, tree, item_list, count):\n",
    "    if items[0] in tree.children:\n",
    "        #判断items的第一个结点是否已作为子结点\n",
    "        tree.children[items[0]].add(count)\n",
    "    else:\n",
    "        #创建新的分支\n",
    "        tree.children[items[0]] = node(items[0], count, tree)\n",
    "        #更新相应频繁项集的链表，往后添加\n",
    "        if item_list[items[0]][1] == None:\n",
    "            item_list[items[0]][1] = tree.children[items[0]]\n",
    "        else:\n",
    "            update_item_list(item_list[items[0]][1], tree.children[items[0]])\n",
    "    #递归\n",
    "    if len(items) > 1:\n",
    "        update_FPtree(items[1::], tree.children[items[0]], item_list, count)\n",
    "\n",
    "def crerat_fp_tree(data, minSupport):\n",
    "    #创建每个频繁item的列表item_list\n",
    "    item_list = {}\n",
    "    #根据数据集data汇集每个item数量\n",
    "    for i in data:\n",
    "        for j in i:\n",
    "            item_list[j] = item_list.get(j, 0)+data[i]\n",
    "    #将数据项小于min_support删除掉\n",
    "    for k in list(item_list.keys()):\n",
    "        if item_list[k] < minSupport:\n",
    "            del(item_list[k])\n",
    "    #创建频繁项集的索引\n",
    "    frequent_item = set(item_list.keys())\n",
    "    #将item_list的格式改为值及指向下一个item出现处的指针\n",
    "    for k in item_list:\n",
    "        item_list[k] = [item_list[k], None]\n",
    "    #创建FP树的树根tree结点\n",
    "    tree = node('', 1, None)\n",
    "    for i,count in data.items():\n",
    "        #首先筛选出满足最小支持度的项集\n",
    "        item = {}\n",
    "        for j in i:\n",
    "            if j in frequent_item: \n",
    "                item[j] = item_list[j][0] # element : count\n",
    "        if len(item) > 0:\n",
    "            #按照频数对每个item项集进行排序并更新fp树\n",
    "            ordered_item = [v[0] for v in sorted(item.items(), key=lambda p:(p[1], -ord(p[0][0])), reverse=True)]\n",
    "            update_FPtree(ordered_item, tree, item_list, count)\n",
    "    return tree, item_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据每个项集出现的频数，设置最小支持度minSupport为100进行fp树的构建，树根结点为变量tree，频繁项集表头指针存放在变量item_list中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "minSupport=100\n",
    "tree, item_list = crerat_fp_tree(comb_data, minSupport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照课件上给定步骤构造指定item的条件模式基，代码如函数create_conditional_database所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conditional_database(item, item_list):\n",
    "    #tree_node变量指向传参item在FP树中的第一个结点\n",
    "    tree_node = item_list[item][1] \n",
    "    conditional_database={}\n",
    "    #递归的沿着tree_node结点向上寻找一条到根节点的路径并保存在path中，之后在进行下一个item位置继续寻找path\n",
    "    while tree_node != None:\n",
    "        path = []\n",
    "        temp_node=tree_node\n",
    "        if(temp_node.parent!=None):\n",
    "            while temp_node.parent!=None:\n",
    "                path.append(temp_node.name)\n",
    "                temp_node=temp_node.parent\n",
    "            if len(path) > 1:\n",
    "                conditional_database[frozenset(path[1:])] = tree_node.count\n",
    "            tree_node = tree_node.nodeLink \n",
    "    return conditional_database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对每一个频繁项都建立一棵条件FP树，然后对每个条件FP树递归地挖掘，最后可以得到所有满足最小支持度的频繁项集，代码如函数mine_FPtree所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_FPtree(tree, item_list, minSupport, l, result):\n",
    "    #最开始的频繁项集是item_list中的各元素\n",
    "    t = [v[0] for v in sorted(item_list.items(), key=lambda p:p[1][0])]\n",
    "    #对每个频繁项进行处理\n",
    "    for i in t: \n",
    "        new_t = l.copy()\n",
    "        new_t.append(i)\n",
    "        if(len(new_t)>1):\n",
    "            result.append([new_t,item_list[i][0]])\n",
    "        #当前频繁项集的条件模式基\n",
    "        conditional_database_i = create_conditional_database(i, item_list) \n",
    "        #构造当前频繁项的条件FP树\n",
    "        new_tree, new_item_list = crerat_fp_tree(conditional_database_i, minSupport) \n",
    "        if new_item_list != None:\n",
    "            #递归挖掘条件FP树\n",
    "            mine_FPtree(new_tree, new_item_list, minSupport, new_t, result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照最小支持度minSupport=100的要求提取的所有频繁项集保存在freItems列表中，总共有2835个满足要求的频繁项集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqItems = []\n",
    "mine_FPtree(tree, item_list, minSupport, list([]), freqItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "筛选出其中一部分频繁项集以及其支持度进行展示，如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Freightliner Trucks', 'Pilot Travel Centers'] 101\n",
      "['Freightliner Trucks', 'TravelCenters of America'] 108\n",
      "[\"Buddy's\", 'Stripes Convenience Stores'] 119\n",
      "['Harps Food Store', 'Sonic'] 112\n",
      "['Harps Food Store', 'Sonic', 'walmart'] 105\n",
      "['Harps Food Store', 'walmart'] 119\n",
      "['Acme Markets', 'Wawa'] 105\n",
      "['Bomgaars', \"Casey's General Stores\"] 120\n",
      "['County Market', \"Casey's General Stores\"] 108\n",
      "['Simple Simon‚Äôs Pizza', 'Sonic'] 109\n",
      "['Simple Simon‚Äôs Pizza', 'walmart'] 110\n",
      "['Pet Pros', 'starbucks'] 111\n",
      "[\"Spencer's\", 'Wegmans Food Markets'] 125\n",
      "[\"Coborn's\", 'Holiday Station'] 103\n",
      "['OnCue', 'walmart'] 120\n",
      "['OnCue', 'Phillips 66'] 127\n",
      "['Chrysler', 'Jeep'] 172\n",
      "['Chrysler', 'Jeep', 'Dodge'] 170\n",
      "['Chrysler', 'Dodge'] 178\n",
      "['The Exchange', 'QuikTrip'] 146\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(freqItems)):\n",
    "    if(i<20):\n",
    "        print(freqItems[i][0],freqItems[i][1])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.导出关联规则，计算其支持度和置信度;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置参数最小支持度为100、最小置信度为0.75提取关联规则，最终得到61组关联规则,其中每一条规则有4项，第一个为条件，第二项为全集，第三项为支持度，第四项为置信度，例如[\"Buddy's\",[\"Buddy's\",'Stripes Convenience Stores'], 119, 0.9296875]表示Buddy's->Stripes Convenience Stores[119,0.9296875]\n",
    "。提取代码如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "minSupport=100\n",
    "minConfidence=0.75\n",
    "assocrules = []\n",
    "for i in range(len(freqItems)):\n",
    "    t=freqItems[i][0]\n",
    "    count=freqItems[i][1]\n",
    "    for j in range(len(t)):\n",
    "        item=t[j]\n",
    "        count_item=item_list[item][0]\n",
    "        if(count/count_item>minConfidence):\n",
    "            assocrules.append([item,t,count,count/count_item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "筛选出其中一部分关联规则以及其支持度与置信度结果进行展示，如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Freightliner Trucks', ['Freightliner Trucks', 'Pilot Travel Centers'], 101, 0.9017857142857143]\n",
      "['Freightliner Trucks', ['Freightliner Trucks', 'TravelCenters of America'], 108, 0.9642857142857143]\n",
      "[\"Buddy's\", [\"Buddy's\", 'Stripes Convenience Stores'], 119, 0.9296875]\n",
      "['Harps Food Store', ['Harps Food Store', 'Sonic'], 112, 0.8682170542635659]\n",
      "['Harps Food Store', ['Harps Food Store', 'Sonic', 'walmart'], 105, 0.813953488372093]\n",
      "['Harps Food Store', ['Harps Food Store', 'walmart'], 119, 0.9224806201550387]\n",
      "['Acme Markets', ['Acme Markets', 'Wawa'], 105, 0.7894736842105263]\n",
      "['Bomgaars', ['Bomgaars', \"Casey's General Stores\"], 120, 0.8759124087591241]\n",
      "['County Market', ['County Market', \"Casey's General Stores\"], 108, 0.7659574468085106]\n",
      "['Simple Simon‚Äôs Pizza', ['Simple Simon‚Äôs Pizza', 'Sonic'], 109, 0.7730496453900709]\n",
      "['Simple Simon‚Äôs Pizza', ['Simple Simon‚Äôs Pizza', 'walmart'], 110, 0.7801418439716312]\n",
      "['Pet Pros', ['Pet Pros', 'starbucks'], 111, 0.7655172413793103]\n",
      "[\"Spencer's\", [\"Spencer's\", 'Wegmans Food Markets'], 125, 0.8445945945945946]\n",
      "['OnCue', ['OnCue', 'walmart'], 120, 0.759493670886076]\n",
      "['OnCue', ['OnCue', 'Phillips 66'], 127, 0.8037974683544303]\n",
      "['Chrysler', ['Chrysler', 'Jeep'], 172, 0.9555555555555556]\n",
      "['Jeep', ['Chrysler', 'Jeep'], 172, 0.900523560209424]\n",
      "['Chrysler', ['Chrysler', 'Jeep', 'Dodge'], 170, 0.9444444444444444]\n",
      "['Jeep', ['Chrysler', 'Jeep', 'Dodge'], 170, 0.8900523560209425]\n",
      "['Dodge', ['Chrysler', 'Jeep', 'Dodge'], 170, 0.8415841584158416]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(assocrules)):\n",
    "    if(i<20):\n",
    "        print(assocrules[i])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.对规则进行评价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用Lift以及Allconf两种指标对提取出来的关联规则进行评价，代码如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_number=len(all_data)\n",
    "for i in range(len(assocrules)):\n",
    "    sab=assocrules[i][2]/sum_number\n",
    "    sa=item_list[assocrules[i][1][0]][0]/sum_number\n",
    "    sb=item_list[assocrules[i][1][1]][0]/sum_number\n",
    "    lift=sab/(sa*sb)\n",
    "    allconf=(sab/sa+sab/sb)/2\n",
    "    assocrules[i]=[assocrules[i][0],assocrules[i][1],assocrules[i][2],assocrules[i][3],lift,allconf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "筛选出其中一部分结果进行展示，其中lift以及Allconf评价指标结果见每一项后两个数所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Freightliner Trucks', ['Freightliner Trucks', 'Pilot Travel Centers'], 101, 0.9017857142857143, 19.594556117061394, 0.4568180008715912]\n",
      "['Freightliner Trucks', ['Freightliner Trucks', 'TravelCenters of America'], 108, 0.9642857142857143, 220.74037612572837, 0.5488919300723998]\n",
      "[\"Buddy's\", [\"Buddy's\", 'Stripes Convenience Stores'], 119, 0.9296875, 99.57872596153845, 0.499256705465587]\n",
      "['Harps Food Store', ['Harps Food Store', 'Sonic'], 112, 0.8682170542635659, 15.768139740142452, 0.439600338448837]\n",
      "['Harps Food Store', ['Harps Food Store', 'Sonic', 'walmart'], 105, 0.813953488372093, 14.78263100638355, 0.41212531729578467]\n",
      "['Harps Food Store', ['Harps Food Store', 'walmart'], 119, 0.9224806201550387, 3.941602913764295, 0.46261311244012376]\n",
      "['Acme Markets', ['Acme Markets', 'Wawa'], 105, 0.7894736842105263, 15.956018771144821, 0.40046640665835714]\n",
      "['Bomgaars', ['Bomgaars', \"Casey's General Stores\"], 120, 0.8759124087591241, 17.62608352877632, 0.44447581754918064]\n",
      "['County Market', ['County Market', \"Casey's General Stores\"], 108, 0.7659574468085106, 15.413447511334185, 0.38884637525691207]\n",
      "['Simple Simon‚Äôs Pizza', ['Simple Simon‚Äôs Pizza', 'Sonic'], 109, 0.7730496453900709, 14.03975512196954, 0.3918695319232398]\n",
      "['Simple Simon‚Äôs Pizza', ['Simple Simon‚Äôs Pizza', 'walmart'], 110, 0.7801418439716312, 3.333413513696606, 0.3913398989596516]\n",
      "['Pet Pros', ['Pet Pros', 'starbucks'], 111, 0.7655172413793103, 10.402732204487718, 0.386831118488305]\n",
      "[\"Spencer's\", [\"Spencer's\", 'Wegmans Food Markets'], 125, 0.8445945945945946, 95.90006545478647, 0.4606173463469601]\n",
      "['OnCue', ['OnCue', 'walmart'], 120, 0.759493670886076, 3.2451873792719543, 0.38113117395994994]\n",
      "['OnCue', ['OnCue', 'Phillips 66'], 127, 0.8037974683544303, 32.75196139867152, 0.4158701313169292]\n",
      "['Chrysler', ['Chrysler', 'Jeep'], 172, 0.9555555555555556, 926.503664921466, 0.9280395578824898]\n",
      "['Jeep', ['Chrysler', 'Jeep'], 172, 0.900523560209424, 926.503664921466, 0.9280395578824898]\n",
      "['Chrysler', ['Chrysler', 'Jeep', 'Dodge'], 170, 0.9444444444444444, 915.7303664921467, 0.9172484002326935]\n",
      "['Jeep', ['Chrysler', 'Jeep', 'Dodge'], 170, 0.8900523560209425, 915.7303664921467, 0.9172484002326935]\n",
      "['Dodge', ['Chrysler', 'Jeep', 'Dodge'], 170, 0.8415841584158416, 915.7303664921467, 0.9172484002326935]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(assocrules)):\n",
    "    if(i<20):\n",
    "        print(assocrules[i])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.对挖掘结果进行分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从提取出的关联规则中筛选其中两条规则进行分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cracker Barrel', ['Cracker Barrel', 'mcdonalds'], 622, 0.7794486215538847, 3.107140550862703, 0.39641867330573244]\n"
     ]
    }
   ],
   "source": [
    "temp=sorted(assocrules, key=lambda p:p[2], reverse=True)\n",
    "print(temp[11]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）根据该条关联规则显示，支持度为622，置信度为77.9%，即既访问Cracker Barrel同时又访问mcdonalds的人数共有622人次，在访问Cracker Barrel的人群中有77.9%的人同样会访问mcdonalds，\n",
    "该条规则的评价lift指标为3大于1表示具有正相关关系，而allconf指标显示为0.01小于0.5应该为负相关，这说明该规则受到零事务的影响导致lift评价指标出现问题，由该项规则可以发现lift指标受零事务的影响很大，而实际上我们去Cracker Barrel和去McDonald的相关性不应该取决于两者都不访问的记录，这一点正如课上所讲的lift和卡方指标的劣势，即容易受到数据记录大小的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jeep', ['Jeep', 'Dodge'], 180, 0.9424083769633508, 863.9972007671972, 0.916748742937121]\n"
     ]
    }
   ],
   "source": [
    "print(temp[36]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）根据该条关联规则显示，支持度为180，置信度为94.2%，既访问Jeep同时又访问Dodge的人数共有188人次，在访问Jeep的人群中有94.2%的人同样会访问Dodge，该条规则的评价lift指标为863远远大于1表示具有正相关关系，而allconf指标显示为0.89大于0.5同样表示正相关关系，这说明jeep和dodge确实存在着强烈的正相关关系，而在实际中Jeep和Dodge是两款车的品牌都是克莱斯勒的产品，基本是同一个平台，所以两个品牌之间有非常强的共性，想购买Jeep车的人往往也会去Dodge看看，这一点比较贴合实际生活。所以可以在浏览Jeep的人群中宣传Dodge可能是一件比较有效率销售策略。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
